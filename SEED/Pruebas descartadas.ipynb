{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASE UTILIZADA PARA LA ECHO STATE NETWORK CON TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ESN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, reservoir_size, output_dim, leaking_rate=0.3, spectral_radius=0.9):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.leaking_rate = leaking_rate\n",
    "        \n",
    "        self.W_in = nn.Parameter(torch.randn(reservoir_size, input_dim) * 0.5, requires_grad=False)\n",
    "        \n",
    "        W = torch.randn(reservoir_size, reservoir_size)\n",
    "        W *= spectral_radius / torch.max(torch.abs(torch.linalg.eigvals(W)))\n",
    "        \n",
    "        connectivity_mask = torch.rand(reservoir_size, reservoir_size) < 0.1\n",
    "        self.W = nn.Parameter(W * connectivity_mask.float(), requires_grad=False)\n",
    "        \n",
    "        self.W_out = nn.Linear(reservoir_size, output_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len, input_dim = inputs.shape\n",
    "        states = torch.zeros(batch_size, self.reservoir_size)\n",
    "        \n",
    "        all_states = []\n",
    "        for t in range(seq_len):\n",
    "            current_input = inputs[:,t,:]\n",
    "            preactivation = torch.mm(current_input, self.W_in.T) + torch.mm(states, self.W.T)\n",
    "            states = (1 - self.leaking_rate)*states + self.leaking_rate * torch.tanh(preactivation)\n",
    "            all_states.append(states.unsqueeze(1))\n",
    "            \n",
    "        return torch.cat(all_states, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir datos de entrenamiento\n",
    "X_train = torch.from_numpy(X_train).float()  # Shape (n, 100, 62)\n",
    "y_train = torch.from_numpy(y_train).long()   # Shape (n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = ESN(input_dim=62, reservoir_size=200, output_dim=3)\n",
    "optimizer = torch.optim.Adam(esn.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(15):\n",
    "    print(\"Epoch \", epoch)\n",
    "    reservoir_states = esn(X_train)\n",
    "    outputs = esn.W_out(reservoir_states[:,-1,:])  # Último estado para clasificación\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir datos de entrenamiento\n",
    "X_test = torch.from_numpy(X_test).float()  # Shape (n, 100, 62)\n",
    "y_test = torch.from_numpy(y_test).long()   # Shape (n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación\n",
    "with torch.no_grad():\n",
    "    test_states = esn(X_test)\n",
    "    y_pred = torch.argmax(esn.W_out(test_states[:,-1,:]), dim=1)\n",
    "    accuracy = (y_pred == y_test).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTADOS DE APROXIMADAMENTE EL 33% DE ACIERTO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312gpu",
   "language": "python",
   "name": "py312gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
